From 28658fb75710deb766b2329f82c3b1f80444a733 Mon Sep 17 00:00:00 2001
From: Oliver Pinter <oliver.pntr@gmail.com>
Date: Tue, 16 Apr 2013 01:32:25 +0200
Subject: [PATCH] added SMAP support for FreeBSD against r250423 with
 ksp_kpatch boot time patching framework

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added	void clac(void) and	void stac(void) to cpufunc.h

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added STAC/CLAC instruction and added config options

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added basic support for SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added stac/clac in support.S around userspace memory access

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added RFLAGS.AC clearing to exception.S related to SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added RFLAGS.AC clearing to ia32_exception.S related to SMAP

added RFLAGS.AC clearing to asmacros.h related to SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

clac and stac functions depend on INTEL_SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added trap handler to SMAP

For security reason, when PF occured by SMAP, the kernel should paniced.

" [...]

The above items imply that the error code delivered by a page-fault exception
due to SMAP is either 1 (for reads) or 3 (for writes).
Note that the only page-fault exceptions that deliver an error code of 1 are
those induced by SMAP. (If CR0.WP = 1, some page-fault exceptions may deliver an
error code of 3 even if CR4.SMAP = 0.)

[...]" - intel 319433-014.pdf 9.3.3

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

fixed smap trap handler

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

fixed the trap handler 2.

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

SMAP - fixed commend in trap.c

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added ksp_kpatch framework

This framework provided a boot time kernel patching mechanizm.

The patching depends on a condition, these include the following:
* cpu feature status words:
	- CPU_FEATURE
	- CPU_FEATURE2
	- AMD_FEATURE
	- AMD_FEATURE2
	- VIA_FEATURE_RNG
	- VIA_FEATURE_XCRYPT
	- CPU_STDEXT_FEATURE
* and feature bit, which defined in sys/x86/include/specialreg.h

usage example:

\#define _ksp_kpatch_clac                                               \
89071:                                                                  \
        .byte 0x0f,0x1f,0x00 ;                  /* patchable - nop */   \
89072:                                                                  \
        .pushsection set_ksp_kpatch_set, "a" ;                          \
                .quad   89071b ;                /* &patchable */        \
                .quad   89073f ;                /* &patch */            \
                .int    CPUID_STDEXT_SMAP ;     /* feature_bit*/        \
                .word   CPU_STDEXT_FEATURE ;                            \
                .byte   89072b-89071b ;                                 \
                .byte   89074f-89073f ;                                 \
        .popsection ;                                                   \
        .pushsection set_ksp_kpatch_patch_set, "ax" ;                   \
89073:                                                                  \
                .byte 0x0f,0x01,0xca ;          /* patch - clac */      \
89074:                                                                  \
        .popsection

This defined a ksp_kpatch, in initial state, the original location of
binary contained a multi byte nop, and when a contition matched, then
overwrited by the patch, in this case the byte series of clac.

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

hook in ksp_kpatch

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>
---
 sys/amd64/amd64/exception.S                 |   6 +
 sys/amd64/amd64/identcpu.c                  |  28 ++++-
 sys/amd64/amd64/initcpu.c                   |  12 +-
 sys/amd64/amd64/ksp_kpatch.c                | 170 ++++++++++++++++++++++++++++
 sys/amd64/amd64/machdep.c                   |   4 +
 sys/amd64/amd64/pmap.c                      |   6 +
 sys/amd64/amd64/support.S                   |  33 ++++++
 sys/amd64/amd64/trap.c                      |  21 +++-
 sys/amd64/ia32/ia32_exception.S             |   1 +
 sys/amd64/include/asmacros.h                |   3 +-
 sys/amd64/include/cpufunc.h                 |  25 ++++
 sys/amd64/include/ksp_kpatch.h              |  58 ++++++++++
 sys/amd64/include/ksp_kpatch_asmacros.h     |  55 +++++++++
 sys/amd64/include/ksp_kpatch_common.h       |  40 +++++++
 sys/amd64/include/ksp_kpatch_instructions.h |  65 +++++++++++
 sys/amd64/include/ksp_kpatch_smap.h         |  69 +++++++++++
 sys/amd64/include/smap_instr.h              |  16 +++
 sys/conf/NOTES                              |   4 +
 sys/conf/files.amd64                        |   1 +
 sys/conf/options.amd64                      |   6 +
 sys/x86/include/specialreg.h                |   1 +
 21 files changed, 613 insertions(+), 11 deletions(-)
 create mode 100644 sys/amd64/amd64/ksp_kpatch.c
 create mode 100644 sys/amd64/include/ksp_kpatch.h
 create mode 100644 sys/amd64/include/ksp_kpatch_asmacros.h
 create mode 100644 sys/amd64/include/ksp_kpatch_common.h
 create mode 100644 sys/amd64/include/ksp_kpatch_instructions.h
 create mode 100644 sys/amd64/include/ksp_kpatch_smap.h
 create mode 100644 sys/amd64/include/smap_instr.h

diff --git a/sys/amd64/amd64/exception.S b/sys/amd64/amd64/exception.S
index 89ad638..2956efc 100644
--- a/sys/amd64/amd64/exception.S
+++ b/sys/amd64/amd64/exception.S
@@ -42,6 +42,7 @@
 #include <machine/asmacros.h>
 #include <machine/psl.h>
 #include <machine/trap.h>
+#include <machine/smap_instr.h>
 #include <machine/specialreg.h>
 
 #include "assym.s"
@@ -196,6 +197,7 @@ alltraps_pushregs_no_rdi:
 	movq	%r15,TF_R15(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	FAKE_MCOUNT(TF_RIP(%rsp))
 #ifdef KDTRACE_HOOKS
 	/*
@@ -276,6 +278,7 @@ IDTVEC(dblfault)
 	movw	%ds,TF_DS(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	testb	$SEL_RPL_MASK,TF_CS(%rsp) /* Did we come from kernel? */
 	jz	1f			/* already running with kernel GS.base */
 	swapgs
@@ -379,6 +382,7 @@ IDTVEC(fast_syscall)
 	movq	%r15,TF_R15(%rsp)	/* C preserved */
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	FAKE_MCOUNT(TF_RIP(%rsp))
 	movq	PCPU(CURTHREAD),%rdi
 	movq	%rsp,TD_FRAME(%rdi)
@@ -474,6 +478,7 @@ IDTVEC(nmi)
 	movw	%ds,TF_DS(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	xorl	%ebx,%ebx
 	testb	$SEL_RPL_MASK,TF_CS(%rsp)
 	jnz	nmi_fromuserspace
@@ -533,6 +538,7 @@ nmi_calltrap:
 
 	shrq	$3,%rcx		/* trap frame size in long words */
 	cld
+	CLAC
 	rep
 	movsq			/* copy trapframe */
 
diff --git a/sys/amd64/amd64/identcpu.c b/sys/amd64/amd64/identcpu.c
index ec5a2aa..856223d 100644
--- a/sys/amd64/amd64/identcpu.c
+++ b/sys/amd64/amd64/identcpu.c
@@ -391,12 +391,14 @@ printcpuinfo(void)
 				       /* RDFSBASE/RDGSBASE/WRFSBASE/WRGSBASE */
 				       "\001GSFSBASE"
 				       "\002TSCADJ"
+				       "\003<b2>"
 				       /* Bit Manipulation Instructions */
 				       "\004BMI1"
 				       /* Hardware Lock Elision */
 				       "\005HLE"
 				       /* Advanced Vector Instructions 2 */
 				       "\006AVX2"
+				       "\007<b6>"
 				       /* Supervisor Mode Execution Prot. */
 				       "\010SMEP"
 				       /* Bit Manipulation Instructions */
@@ -406,12 +408,29 @@ printcpuinfo(void)
 				       "\013INVPCID"
 				       /* Restricted Transactional Memory */
 				       "\014RTM"
+				       "\015<b12>"
+				       "\016<b13>"
+				       "\017<b14>"
+				       "\020<b15>"
+				       "\021<b16>"
+				       "\022<b17>"
 				       /* Enhanced NRBG */
-				       "\022RDSEED"
+				       "\023RDSEED"
 				       /* ADCX + ADOX */
-				       "\023ADX"
+				       "\024ADX"
 				       /* Supervisor Mode Access Prevention */
-				       "\024SMAP"
+				       "\025SMAP"
+				       "\026<b21>"
+				       "\027<b22>"
+				       "\030<b23>"
+				       "\031<b24>"
+				       "\032<b25>"
+				       "\033<b26>"
+				       "\034<b27>"
+				       "\035<b28>"
+				       "\036<b29>"
+				       "\037<b30>"
+				       "\040<b31>"
 				       );
 			}
 
@@ -545,6 +564,9 @@ identify_cpu(void)
 		if (cpu_feature2 & CPUID2_HV) {
 			cpu_stdext_disable = CPUID_STDEXT_FSGSBASE |
 			    CPUID_STDEXT_SMEP;
+#ifdef	INTEL_SMAP
+			cpu_stdext_disable |= CPUID_STDEXT_SMAP;
+#endif	/* INTEL_SMAP */
 		} else
 			cpu_stdext_disable = 0;
 		TUNABLE_INT_FETCH("hw.cpu_stdext_disable", &cpu_stdext_disable);
diff --git a/sys/amd64/amd64/initcpu.c b/sys/amd64/amd64/initcpu.c
index 4abed4c..1f0ae6c 100644
--- a/sys/amd64/amd64/initcpu.c
+++ b/sys/amd64/amd64/initcpu.c
@@ -165,13 +165,17 @@ initializecpu(void)
 		cr4 |= CR4_FSGSBASE;
 
 	/*
-	 * Postpone enabling the SMEP on the boot CPU until the page
-	 * tables are switched from the boot loader identity mapping
-	 * to the kernel tables.  The boot loader enables the U bit in
-	 * its tables.
+	 * Postpone enabling the SMEP and the SMAP on the boot CPU until
+	 * the page tables are switched from the boot loader identity
+	 * mapping to the kernel tables.
+	 * The boot loader enables the U bit in its tables.
 	 */
 	if (!IS_BSP() && (cpu_stdext_feature & CPUID_STDEXT_SMEP))
 		cr4 |= CR4_SMEP;
+#ifdef	INTEL_SMAP
+	if (!IS_BSP() && (cpu_stdext_feature & CPUID_STDEXT_SMAP))
+		cr4 |= CR4_SMAP;
+#endif	/* INTEL_SMAP */
 	load_cr4(cr4);
 	if ((amd_feature & AMDID_NX) != 0) {
 		msr = rdmsr(MSR_EFER) | EFER_NXE;
diff --git a/sys/amd64/amd64/ksp_kpatch.c b/sys/amd64/amd64/ksp_kpatch.c
new file mode 100644
index 0000000..4dce844
--- /dev/null
+++ b/sys/amd64/amd64/ksp_kpatch.c
@@ -0,0 +1,170 @@
+/*-
+ * Copyright (c) 2013, by Oliver Pinter <oliver.pntr at gmail.com>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. The name of the developer may NOT be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD$
+ */
+
+#include <sys/cdefs.h>
+/* #include <sys/linker_set.h> */
+#include <sys/param.h>
+#include <sys/systm.h>
+
+#include <machine/cpufunc.h>
+#include <machine/ksp_kpatch.h>
+#include <machine/ksp_kpatch_common.h>
+#include <machine/ksp_kpatch_instructions.h>
+#include <machine/md_var.h>
+#include <machine/specialreg.h>
+
+const unsigned char intelnops[] = {
+	INTEL_NOP1,
+	INTEL_NOP2,
+	INTEL_NOP3,
+	INTEL_NOP4,
+	INTEL_NOP5,
+	INTEL_NOP6,
+	INTEL_NOP7,
+	INTEL_NOP8,
+	INTEL_NOP9
+};
+
+const unsigned char * const intel_nops[INTEL_NOP_MAX + 1] = {
+	NULL,
+	&intelnops[1],
+	&intelnops[2],
+	&intelnops[3],
+	&intelnops[4],
+	&intelnops[5],
+	&intelnops[6],
+	&intelnops[7],
+	&intelnops[8],
+	&intelnops[9]
+};
+
+extern struct ksp_kpatch  __start_set_ksp_kpatch_set[];
+extern struct ksp_kpatch  __stop_set_ksp_kpatch_set[];
+
+static void
+ksp_pad_with_nops(void *_buffer, unsigned int len)
+{
+	unsigned int	nop_len;
+	unsigned char	*buffer=_buffer;
+
+	while (len > 0) {
+		nop_len=(len > INTEL_NOP_MAX) ? INTEL_NOP_MAX : len;
+		memcpy(buffer, intel_nops[nop_len], nop_len);
+		buffer += nop_len;
+		len -= nop_len;
+	}
+}
+
+void
+ksp_kpatch_apply(struct ksp_kpatch *patch)
+{
+	__uint8_t		patch_buffer[KSP_KPATCH_MAXLEN];
+	int			patch_needed=0;
+
+	dprintf("ksp_kpatch: patch start at 0x%016lx\n", (long)patch);
+	dprintf("ksp_kpatch: patch_size: %d - patchable size: %d ...\n",
+				patch->patch_size, patch->patchable_size);
+	KASSERT(patch->patch_size == patch->patchable_size,
+				("ksp_kpatch: patch size > patchable size\n"));
+
+	switch (patch->feature_selector) {
+	case	CPU_FEATURE:
+			if ((cpu_feature & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	case	CPU_FEATURE2:
+			if ((cpu_feature2 & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	case	AMD_FEATURE:
+			if ((amd_feature & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	case	AMD_FEATURE2:
+			if ((amd_feature2 & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	case	VIA_FEATURE_RNG:
+			if ((via_feature_rng & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	case	VIA_FEATURE_XCRYPT:
+			if ((via_feature_xcrypt & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	case	CPU_STDEXT_FEATURE:
+			if ((cpu_stdext_feature & patch->feature_bit) != 0)
+				patch_needed=1;
+			break;
+	default:
+			dprintf("ksp_kpatch: no matching selector word\n");
+			patch_needed=0;
+			return;
+	}
+	if (patch_needed != 1) {
+		dprintf("ksp_kpatch: skipping patch at 0x%016lx", (long)patch);
+
+		return;
+	}
+
+	dprintf("ksp_kpatch: apply patch ...");
+	memcpy(patch_buffer, patch->patch_address, patch->patch_size);
+	ksp_pad_with_nops(patch_buffer,
+			patch->patchable_size-patch->patch_size);
+
+	/*
+	 * Write the previouly assembled instraction patch
+	 */
+	memcpy(patch->patchable_address, patch_buffer, patch->patchable_size);
+}
+
+void
+ksp_kpatch(void)
+{
+	struct ksp_kpatch	*patch, *start, *stop;
+	int			patch_count;
+
+	start=__start_set_ksp_kpatch_set;
+	stop=__stop_set_ksp_kpatch_set;
+
+	patch_count=stop-start;
+	if (patch_count == 0) {
+		dprintf("ksp_kpatch: no patches\n");
+		dprintf("ksp_kpatch: skip kernel patching\n");
+
+		return;
+	}
+	dprintf("ksp_kpatch: patch count	: %d\n", patch_count);
+	dprintf("ksp_kpatch: patch set start	: 0x%016lx\n", (long)start);
+	dprintf("ksp_kpatch: patch set end  	: 0x%016lx\n", (long)stop);
+	for (patch=start; patch<stop; patch++) {
+		dprintf("ksp_kpatch_set: try patch at 0x%016lx\n",
+								(long)patch);
+		ksp_kpatch_apply(patch);
+	}
+}
+
diff --git a/sys/amd64/amd64/machdep.c b/sys/amd64/amd64/machdep.c
index a543421..74b56a4 100644
--- a/sys/amd64/amd64/machdep.c
+++ b/sys/amd64/amd64/machdep.c
@@ -115,6 +115,7 @@ __FBSDID("$FreeBSD$");
 #include <machine/clock.h>
 #include <machine/cpu.h>
 #include <machine/cputypes.h>
+#include <machine/ksp_kpatch.h>
 #include <machine/intr_machdep.h>
 #include <x86/mca.h>
 #include <machine/md_var.h>
@@ -1800,6 +1801,9 @@ hammer_time(u_int64_t modulep, u_int64_t physfree)
 	initializecpu();	/* Initialize CPU registers */
 	initializecpucache();
 
+	/* patching the kernel text for new instructions */
+	ksp_kpatch();
+
 	/* doublefault stack space, runs on ist1 */
 	common_tss[0].tss_ist1 = (long)&dblfault_stack[sizeof(dblfault_stack)];
 
diff --git a/sys/amd64/amd64/pmap.c b/sys/amd64/amd64/pmap.c
index 1b1c86c..9847fbe 100644
--- a/sys/amd64/amd64/pmap.c
+++ b/sys/amd64/amd64/pmap.c
@@ -98,6 +98,7 @@ __FBSDID("$FreeBSD$");
  *	and to when physical maps must be made correct.
  */
 
+#include "opt_cpu.h"
 #include "opt_pmap.h"
 #include "opt_vm.h"
 
@@ -665,6 +666,11 @@ pmap_bootstrap(vm_paddr_t *firstaddr)
 	if (cpu_stdext_feature & CPUID_STDEXT_SMEP)
 		load_cr4(rcr4() | CR4_SMEP);
 
+#ifdef	INTEL_SMAP
+	if (cpu_stdext_feature & CPUID_STDEXT_SMAP)
+		load_cr4(rcr4() | CR4_SMAP);
+#endif	/* INTEL_SMAP */
+
 	/*
 	 * Initialize the kernel pmap (which is statically allocated).
 	 */
diff --git a/sys/amd64/amd64/support.S b/sys/amd64/amd64/support.S
index 77dbf63..9c12087 100644
--- a/sys/amd64/amd64/support.S
+++ b/sys/amd64/amd64/support.S
@@ -35,6 +35,7 @@
 #include <machine/asmacros.h>
 #include <machine/intr_machdep.h>
 #include <machine/pmap.h>
+#include <machine/smap_instr.h>
 
 #include "assym.s"
 
@@ -244,12 +245,16 @@ ENTRY(copyout)
 
 	shrq	$3,%rcx
 	cld
+	STAC
 	rep
 	movsq
+	CLAC
 	movb	%dl,%cl
 	andb	$7,%cl
+	STAC
 	rep
 	movsb
+	CLAC
 
 done_copyout:
 	xorl	%eax,%eax
@@ -290,12 +295,16 @@ ENTRY(copyin)
 	movb	%cl,%al
 	shrq	$3,%rcx				/* copy longword-wise */
 	cld
+	STAC
 	rep
 	movsq
+	CLAC
 	movb	%al,%cl
 	andb	$7,%cl				/* copy remaining bytes */
+	STAC
 	rep
 	movsb
+	CLAC
 
 done_copyin:
 	xorl	%eax,%eax
@@ -324,10 +333,12 @@ ENTRY(casuword32)
 	ja	fusufault
 
 	movl	%esi,%eax			/* old */
+	STAC
 #ifdef SMP
 	lock
 #endif
 	cmpxchgl %edx,(%rdi)			/* new = %edx */
+	CLAC
 
 	/*
 	 * The old value is in %eax.  If the store succeeded it will be the
@@ -353,10 +364,12 @@ ENTRY(casuword)
 	ja	fusufault
 
 	movq	%rsi,%rax			/* old */
+	STAC
 #ifdef SMP
 	lock
 #endif
 	cmpxchgq %rdx,(%rdi)			/* new = %rdx */
+	CLAC
 
 	/*
 	 * The old value is in %eax.  If the store succeeded it will be the
@@ -385,7 +398,9 @@ ENTRY(fuword)
 	cmpq	%rax,%rdi			/* verify address is valid */
 	ja	fusufault
 
+	STAC
 	movq	(%rdi),%rax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fuword64)	
@@ -399,7 +414,9 @@ ENTRY(fuword32)
 	cmpq	%rax,%rdi			/* verify address is valid */
 	ja	fusufault
 
+	STAC
 	movl	(%rdi),%eax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fuword32)
@@ -426,7 +443,9 @@ ENTRY(fuword16)
 	cmpq	%rax,%rdi
 	ja	fusufault
 
+	STAC
 	movzwl	(%rdi),%eax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fuword16)
@@ -439,7 +458,9 @@ ENTRY(fubyte)
 	cmpq	%rax,%rdi
 	ja	fusufault
 
+	STAC
 	movzbl	(%rdi),%eax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fubyte)
@@ -466,7 +487,9 @@ ENTRY(suword)
 	cmpq	%rax,%rdi			/* verify address validity */
 	ja	fusufault
 
+	STAC
 	movq	%rsi,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -482,7 +505,9 @@ ENTRY(suword32)
 	cmpq	%rax,%rdi			/* verify address validity */
 	ja	fusufault
 
+	STAC
 	movl	%esi,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -497,7 +522,9 @@ ENTRY(suword16)
 	cmpq	%rax,%rdi			/* verify address validity */
 	ja	fusufault
 
+	STAC
 	movw	%si,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx		/* restore trashed register */
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -513,7 +540,9 @@ ENTRY(subyte)
 	ja	fusufault
 
 	movl	%esi,%eax
+	STAC
 	movb	%al,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx		/* restore trashed register */
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -555,7 +584,9 @@ ENTRY(copyinstr)
 	decq	%rdx
 	jz	3f
 
+	STAC
 	lodsb
+	CLAC
 	stosb
 	orb	%al,%al
 	jnz	2b
@@ -584,7 +615,9 @@ cpystrflt_x:
 	testq	%r9,%r9
 	jz	1f
 	subq	%rdx,%r8
+	STAC
 	movq	%r8,(%r9)
+	CLAC
 1:
 	ret
 END(copyinstr)
diff --git a/sys/amd64/amd64/trap.c b/sys/amd64/amd64/trap.c
index 6fcca81..fc2d303 100644
--- a/sys/amd64/amd64/trap.c
+++ b/sys/amd64/amd64/trap.c
@@ -718,12 +718,27 @@ trap_pfault(frame, usermode)
 
 		map = &vm->vm_map;
 
+#ifdef	INTEL_SMAP
+		/*
+		 * The only case occurs when accessing the address
+		 * without the handler, is a bug, do not try to handle
+		 * it normally, and panic immediately.
+		 * SMAP related.
+		 *
+		 * PGEX_P exception delivered only by SMAP.
+		 * see intel 319433-014.pdf 9.3.3
+		 */
+		if (curpcb->pcb_onfault == NULL &&
+		    !usermode && frame->tf_err & PGEX_P) {
+			trap_fatal(frame, eva);
+			return (-1);
+		}
+#endif	/* INTEL_SMAP */
+
 		/*
 		 * When accessing a usermode address, kernel must be
 		 * ready to accept the page fault, and provide a
-		 * handling routine.  Since accessing the address
-		 * without the handler is a bug, do not try to handle
-		 * it normally, and panic immediately.
+		 * handling routine.
 		 */
 		if (!usermode && (td->td_intr_nesting_level != 0 ||
 		    curpcb->pcb_onfault == NULL)) {
diff --git a/sys/amd64/ia32/ia32_exception.S b/sys/amd64/ia32/ia32_exception.S
index fe1a676..9f13f2f 100644
--- a/sys/amd64/ia32/ia32_exception.S
+++ b/sys/amd64/ia32/ia32_exception.S
@@ -68,6 +68,7 @@ IDTVEC(int0x80_syscall)
 	movq	%r15,TF_R15(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	FAKE_MCOUNT(TF_RIP(%rsp))
 	movq	%rsp, %rdi
 	call	ia32_syscall
diff --git a/sys/amd64/include/asmacros.h b/sys/amd64/include/asmacros.h
index 1fb592a..c985623 100644
--- a/sys/amd64/include/asmacros.h
+++ b/sys/amd64/include/asmacros.h
@@ -167,7 +167,8 @@
 	movw	%es,TF_ES(%rsp) ;					\
 	movw	%ds,TF_DS(%rsp) ;					\
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp) ;				\
-	cld
+	cld ;								\
+	CLAC
 
 #define POP_FRAME							\
 	movq	TF_RDI(%rsp),%rdi ;					\
diff --git a/sys/amd64/include/cpufunc.h b/sys/amd64/include/cpufunc.h
index 881fcd2..3b19b8e 100644
--- a/sys/amd64/include/cpufunc.h
+++ b/sys/amd64/include/cpufunc.h
@@ -39,10 +39,14 @@
 #ifndef _MACHINE_CPUFUNC_H_
 #define	_MACHINE_CPUFUNC_H_
 
+#include "opt_cpu.h"
+
 #ifndef _SYS_CDEFS_H_
 #error this file needs sys/cdefs.h as a prerequisite
 #endif
 
+#include <machine/smap_instr.h>
+
 struct region_descriptor;
 
 #define readb(va)	(*(volatile uint8_t *) (va))
@@ -711,11 +715,31 @@ intr_restore(register_t rflags)
 	write_rflags(rflags);
 }
 
+/*
+ * Intel SMAP related functions (clac and stac)
+ */
+static __inline void
+clac(void)
+{
+#ifdef	INTEL_SMAP
+	__asm __volatile(__STRING(CLAC) : : :);
+#endif	/* INTEL_SMAP */
+}
+
+static __inline void
+stac(void)
+{
+#ifdef	INTEL_SMAP
+	__asm __volatile(__STRING(STAC) : : :);
+#endif	/* INTEL_SMAP */
+}
+
 #else /* !(__GNUCLIKE_ASM && __CC_SUPPORTS___INLINE) */
 
 int	breakpoint(void);
 u_int	bsfl(u_int mask);
 u_int	bsrl(u_int mask);
+void	clac(void);
 void	clflush(u_long addr);
 void	clts(void);
 void	cpuid_count(u_int ax, u_int cx, u_int *p);
@@ -775,6 +799,7 @@ uint64_t rdtsc(void);
 u_long	read_rflags(void);
 u_int	rfs(void);
 u_int	rgs(void);
+void	stac(void);
 void	wbinvd(void);
 void	write_rflags(u_int rf);
 void	wrmsr(u_int msr, uint64_t newval);
diff --git a/sys/amd64/include/ksp_kpatch.h b/sys/amd64/include/ksp_kpatch.h
new file mode 100644
index 0000000..fb7b099
--- /dev/null
+++ b/sys/amd64/include/ksp_kpatch.h
@@ -0,0 +1,58 @@
+/*-
+ * Copyright (c) 2013, by Oliver Pinter <oliver.pntr at gmail.com>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. The name of the developer may NOT be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD$
+ */
+
+#include "opt_ksp.h"
+
+#ifndef	__KSP_KPATCH_H
+#define	__KSP_KPATCH_H
+
+#include <sys/types.h> /* this included cdefs.h too */
+/* #include <sys/linker_set.h> */
+
+#include <machine/ksp_kpatch_common.h>
+
+#ifdef	KSP_KPATCH_DEBUG
+#define	dprintf	printf
+#else	/* KSP_KPATCH_DEBUG */
+#define	dprintf(args...)
+#endif	/* KSP_KPATCH_DEBUG */
+
+struct ksp_kpatch {
+	char	*patchable_address;	/* 64 bit */
+	char	*patch_address;		/* 64 bit */
+	u_int	feature_bit;		/* 32 bit */
+	u_short	feature_selector;	/* 16 bit */
+	u_char	patchable_size;		/*  8 bit */
+	u_char	patch_size;		/*  8 bit */
+};
+
+#define	KSP_KPATCH_MAXLEN	256	/* 8 bit */
+
+extern void ksp_kpatch(void);
+extern void ksp_kpatch_apply(struct ksp_kpatch *patch);
+
+#endif	/* __KSP_KPATCH_H */
diff --git a/sys/amd64/include/ksp_kpatch_asmacros.h b/sys/amd64/include/ksp_kpatch_asmacros.h
new file mode 100644
index 0000000..825d787
--- /dev/null
+++ b/sys/amd64/include/ksp_kpatch_asmacros.h
@@ -0,0 +1,55 @@
+/*-
+ * Copyright (c) 2013, by Oliver Pinter <oliver.pntr at gmail.com>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. The name of the developer may NOT be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD$
+ */
+
+#ifndef	__KSP_KPATCH_ASMACROS_H
+#define	__KSP_KPATCH_ASMACROS_H
+
+#include <sys/cdefs.h>
+
+#include <machine/ksp_kpatch_common.h>
+#include <machine/ksp_kpatch_instructions.h>
+#include <machine/specialreg.h>
+
+#define	KSP_KPATCH(patchable, patch, feature_bit, selector)		\
+89071:									\
+	patchable ;		/* patchable opcodes */			\
+89072:									\
+	.pushsection set_ksp_kpatch_set, "a" ;				\
+		.quad	89701b ;		/* &patchable */	\
+		.quad	89073f ;		/* &patch */		\
+		.int	feature_bit ;		/* feature_bit*/	\
+		.word	selector ;					\
+		.byte	89072b-89071b ;					\
+		.byte	89074f-89073f ;					\
+	.popsection ;							\
+	.pushsection set_ksp_kpatch_patch_set, "ax" ;			\
+89073:									\
+		patch ;		/* opcode paches */			\
+89074:									\
+	.popsection
+
+#endif	/* __KSP_KPATCH_ASMACROS_H */
diff --git a/sys/amd64/include/ksp_kpatch_common.h b/sys/amd64/include/ksp_kpatch_common.h
new file mode 100644
index 0000000..7d90e11
--- /dev/null
+++ b/sys/amd64/include/ksp_kpatch_common.h
@@ -0,0 +1,40 @@
+/*-
+ * Copyright (c) 2013, by Oliver Pinter <oliver.pntr at gmail.com>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. The name of the developer may NOT be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD$
+ */
+
+#ifndef	__KSP_KPATCH_COMMON_H
+#define	__KSP_KPATCH_COMMON_H
+
+#define	KSP_HACK		0
+#define	CPU_FEATURE		1
+#define	CPU_FEATURE2		2
+#define	AMD_FEATURE		3
+#define	AMD_FEATURE2		4
+#define	VIA_FEATURE_RNG		5
+#define	VIA_FEATURE_XCRYPT	6
+#define	CPU_STDEXT_FEATURE	7
+
+#endif	/* __KSP_KPATCH_COMMON_H */
diff --git a/sys/amd64/include/ksp_kpatch_instructions.h b/sys/amd64/include/ksp_kpatch_instructions.h
new file mode 100644
index 0000000..1125267
--- /dev/null
+++ b/sys/amd64/include/ksp_kpatch_instructions.h
@@ -0,0 +1,65 @@
+/*-
+ * Copyright (c) 2013, by Oliver Pinter <oliver.pntr at gmail.com>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. The name of the developer may NOT be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD$
+ */
+
+#ifndef __KSP_KPATCH_INSTRUCTIONS_H
+#define	__KSP_KPATCH_INSTRUCTIONS_H
+
+/*
+ * Intel Instruction Set Reference M-Z
+ * Table 4-12. recommended Multi-Byte Sequeance of NOP Instruction
+ */
+#define	INTEL_NOP1	0x90
+#define	INTEL_NOP2	0x66,0x90
+#define	INTEL_NOP3	0x0f,0x1f,0x00
+#define	INTEL_NOP4	0x0f,0x1f,0x40,0x00
+#define	INTEL_NOP5	0x0f,0x1f,0x44,0x00,0x00
+#define	INTEL_NOP6	0x66,0x0f,0x1f,0x44,0x00,0x00
+#define	INTEL_NOP7	0x0f,0x1f,0x80,0x00,0x00,0x00,0x00
+#define	INTEL_NOP8	0x0f,0x1f,0x84,0x00,0x00,0x00,0x00,0x00
+#define	INTEL_NOP9	0x66,0x0f,0x1f,0x84,0x00,0x00,0x00,0x00,0x00
+
+#define	INTEL_NOP_MAX	9
+
+#define	INTEL_CLAC	0x0f,0x01,0xca
+#define	INTEL_STAC	0x0f,0x01,0xcb
+
+#define	__ASM_MK(_O)	.byte _O
+
+#define	ASM_INTEL_NOP1	__ASM_MK(INTEL_NOP1)
+#define	ASM_INTEL_NOP2	__ASM_MK(INTEL_NOP2)
+#define	ASM_INTEL_NOP3	__ASM_MK(INTEL_NOP3)
+#define	ASM_INTEL_NOP4	__ASM_MK(INTEL_NOP4)
+#define	ASM_INTEL_NOP5	__ASM_MK(INTEL_NOP5)
+#define	ASM_INTEL_NOP6	__ASM_MK(INTEL_NOP6)
+#define	ASM_INTEL_NOP7	__ASM_MK(INTEL_NOP7)
+#define	ASM_INTEL_NOP8	__ASM_MK(INTEL_NOP8)
+#define	ASM_INTEL_NOP9	__ASM_MK(INTEL_NOP9)
+
+#define	ASM_INTEL_CLAC	__ASM_MK(INTEL_CLAC)
+#define	ASM_INTEL_STAC	__ASM_MK(INTEL_STAC)
+
+#endif	/* __KSP_KPATCH_INSTRUCTIONS_H */
diff --git a/sys/amd64/include/ksp_kpatch_smap.h b/sys/amd64/include/ksp_kpatch_smap.h
new file mode 100644
index 0000000..dd5a609
--- /dev/null
+++ b/sys/amd64/include/ksp_kpatch_smap.h
@@ -0,0 +1,69 @@
+/*-
+ * Copyright (c) 2013, by Oliver Pinter <oliver.pntr at gmail.com>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. The name of the developer may NOT be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD$
+ */
+
+#ifndef	__KSP_KPATCH_SMAP_H
+#define	__KSP_KPATCH_SMAP_H
+
+#include <machine/ksp_kpatch_asmacros.h>
+
+#define	_ksp_kpatch_clac						\
+89071:									\
+	.byte 0x0f,0x1f,0x00 ;			/* patchable - nop */	\
+89072:									\
+	.pushsection set_ksp_kpatch_set, "a" ;				\
+		.quad	89071b ;		/* &patchable */	\
+		.quad	89073f ;		/* &patch */		\
+		.int	CPUID_STDEXT_SMAP ;	/* feature_bit*/	\
+		.word	CPU_STDEXT_FEATURE ;				\
+		.byte	89072b-89071b ;					\
+		.byte	89074f-89073f ;					\
+	.popsection ;							\
+	.pushsection set_ksp_kpatch_patch_set, "ax" ;			\
+89073:									\
+		.byte 0x0f,0x01,0xca ;		/* patch - clac */	\
+89074:									\
+	.popsection
+
+#define	_ksp_kpatch_stac						\
+89071:									\
+	.byte 0x0f,0x1f,0x00 ;			/* patchable - nop */	\
+89072:									\
+	.pushsection set_ksp_kpatch_set, "a" ;				\
+		.quad	89071b ;		/* &patchable */	\
+		.quad	89073f ;		/* &patch */		\
+		.int	CPUID_STDEXT_SMAP ;	/* feature_bit*/	\
+		.word	CPU_STDEXT_FEATURE ;				\
+		.byte	89072b-89071b ;					\
+		.byte	89074f-89073f ;					\
+	.popsection ;							\
+	.pushsection set_ksp_kpatch_patch_set, "ax" ;			\
+89073:									\
+		.byte 0x0f,0x01,0xcb ;		/* patch - stac */	\
+89074:									\
+	.popsection
+
+#endif	/* __KSP_KPATCH_SMAP_H */
diff --git a/sys/amd64/include/smap_instr.h b/sys/amd64/include/smap_instr.h
new file mode 100644
index 0000000..518748d
--- /dev/null
+++ b/sys/amd64/include/smap_instr.h
@@ -0,0 +1,16 @@
+#ifndef	__SMAP_INSTRUCTION_H
+#define	__SMAP_INSTRUCTION_H
+
+#include "opt_cpu.h"
+
+#include <machine/ksp_kpatch_smap.h>
+
+#ifdef	INTEL_SMAP
+#define	CLAC	_ksp_kpatch_clac
+#define	STAC	_ksp_kpatch_stac
+#else	/* INTEL_SMAP_SUPPORT */
+#define	CLAC
+#define	STAC
+#endif	/* INTEL_SMAP_SUPPORT */
+
+#endif	/* __SMAP_INSTRUCTION_H */
diff --git a/sys/conf/NOTES b/sys/conf/NOTES
index 48dba77..b27dfeb 100644
--- a/sys/conf/NOTES
+++ b/sys/conf/NOTES
@@ -2963,3 +2963,7 @@ options 	RCTL
 options 	BROOKTREE_ALLOC_PAGES=(217*4+1)
 options 	MAXFILES=999
 
+# Intel SMAP
+# This options supported on Haswell and/or newer CPUs (2013 Juni < ) and
+# makes the kernel unbootable on oldel CPUs.
+options 	INTEL_SMAP	# Intel's hw version of PaX uderef
diff --git a/sys/conf/files.amd64 b/sys/conf/files.amd64
index 2d6db7a..fc4b0cf 100644
--- a/sys/conf/files.amd64
+++ b/sys/conf/files.amd64
@@ -111,6 +111,7 @@ amd64/amd64/identcpu.c		standard
 amd64/amd64/in_cksum.c		optional	inet | inet6
 amd64/amd64/initcpu.c		standard
 amd64/amd64/io.c		optional	io
+amd64/amd64/ksp_kpatch.c	standard
 amd64/amd64/locore.S		standard	no-obj
 amd64/amd64/machdep.c		standard
 amd64/amd64/mem.c		optional	mem
diff --git a/sys/conf/options.amd64 b/sys/conf/options.amd64
index 90348b7..eaedaf9 100644
--- a/sys/conf/options.amd64
+++ b/sys/conf/options.amd64
@@ -72,3 +72,9 @@ ISCI_LOGGING	opt_isci.h
 # hw random number generators for random(4)
 PADLOCK_RNG		opt_cpu.h
 RDRAND_RNG		opt_cpu.h
+
+# Intel supervisor mode access prevention (SMAP)
+INTEL_SMAP		opt_cpu.h
+
+# kernel self protection - ksp
+KSP_DEBUG		opt_ksp.h
diff --git a/sys/x86/include/specialreg.h b/sys/x86/include/specialreg.h
index bf1333f..6bffd43 100644
--- a/sys/x86/include/specialreg.h
+++ b/sys/x86/include/specialreg.h
@@ -73,6 +73,7 @@
 #define	CR4_PCIDE 0x00020000	/* Enable Context ID */
 #define	CR4_XSAVE 0x00040000	/* XSETBV/XGETBV */
 #define	CR4_SMEP 0x00100000	/* Supervisor-Mode Execution Prevention */
+#define	CR4_SMAP 0x00200000	/* Supervisor-Mode Access Prevention */
 
 /*
  * Bits in AMD64 special registers.  EFER is 64 bits wide.
-- 
1.8.2

