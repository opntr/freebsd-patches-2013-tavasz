From fabbfd678f4767c93e0dd5ab9807b60e9757c886 Mon Sep 17 00:00:00 2001
From: Oliver Pinter <oliver.pntr@gmail.com>
Date: Tue, 16 Apr 2013 01:32:25 +0200
Subject: [PATCH] added SMAP support to FreeBSD kernel

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added	void clac(void) and	void stac(void) to cpufunc.h

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added STAC/CLAC instruction and added config options

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added basic support for SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added stac/clac in support.S around userspace memory access

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added RFLAGS.AC clearing to exception.S related to SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added RFLAGS.AC clearing to ia32_exception.S related to SMAP

added RFLAGS.AC clearing to asmacros.h related to SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

clac and stac functions depend on INTEL_SMAP

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

added trap handler to SMAP

For security reason, when PF occured by SMAP, the kernel should paniced.

" [...]

The above items imply that the error code delivered by a page-fault exception
due to SMAP is either 1 (for reads) or 3 (for writes).
Note that the only page-fault exceptions that deliver an error code of 1 are
those induced by SMAP. (If CR0.WP = 1, some page-fault exceptions may deliver an
error code of 3 even if CR4.SMAP = 0.)

[...]" - intel 319433-014.pdf 9.3.3

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

fixed smap trap handler

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

fixed the trap handler 2.

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

SMAP - fixed commend in trap.c

Signed-off-by: Oliver Pinter <oliver.pntr@gmail.com>

	modified:   sys/amd64/amd64/exception.S
	modified:   sys/amd64/amd64/identcpu.c
	modified:   sys/amd64/amd64/initcpu.c
	modified:   sys/amd64/amd64/pmap.c
	modified:   sys/amd64/amd64/support.S
	modified:   sys/amd64/amd64/trap.c
	modified:   sys/amd64/ia32/ia32_exception.S
	modified:   sys/amd64/include/asmacros.h
	modified:   sys/amd64/include/cpufunc.h
	new file:   sys/amd64/include/smap_instr.h
	modified:   sys/conf/NOTES
	modified:   sys/conf/options.amd64
	modified:   sys/x86/include/specialreg.h
---
 sys/amd64/amd64/exception.S     |  6 ++++++
 sys/amd64/amd64/identcpu.c      | 30 ++++++++++++++++++++++++++++++
 sys/amd64/amd64/initcpu.c       | 12 ++++++++----
 sys/amd64/amd64/pmap.c          | 13 +++++++++++++
 sys/amd64/amd64/support.S       | 33 +++++++++++++++++++++++++++++++++
 sys/amd64/amd64/trap.c          | 21 ++++++++++++++++++---
 sys/amd64/ia32/ia32_exception.S |  1 +
 sys/amd64/include/asmacros.h    |  3 ++-
 sys/amd64/include/cpufunc.h     | 23 +++++++++++++++++++++++
 sys/amd64/include/smap_instr.h  | 14 ++++++++++++++
 sys/conf/NOTES                  |  4 ++++
 sys/conf/options.amd64          |  3 +++
 sys/x86/include/specialreg.h    |  2 ++
 13 files changed, 157 insertions(+), 8 deletions(-)
 create mode 100644 sys/amd64/include/smap_instr.h

diff --git a/sys/amd64/amd64/exception.S b/sys/amd64/amd64/exception.S
index 89ad638..2956efc 100644
--- a/sys/amd64/amd64/exception.S
+++ b/sys/amd64/amd64/exception.S
@@ -42,6 +42,7 @@
 #include <machine/asmacros.h>
 #include <machine/psl.h>
 #include <machine/trap.h>
+#include <machine/smap_instr.h>
 #include <machine/specialreg.h>
 
 #include "assym.s"
@@ -196,6 +197,7 @@ alltraps_pushregs_no_rdi:
 	movq	%r15,TF_R15(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	FAKE_MCOUNT(TF_RIP(%rsp))
 #ifdef KDTRACE_HOOKS
 	/*
@@ -276,6 +278,7 @@ IDTVEC(dblfault)
 	movw	%ds,TF_DS(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	testb	$SEL_RPL_MASK,TF_CS(%rsp) /* Did we come from kernel? */
 	jz	1f			/* already running with kernel GS.base */
 	swapgs
@@ -379,6 +382,7 @@ IDTVEC(fast_syscall)
 	movq	%r15,TF_R15(%rsp)	/* C preserved */
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	FAKE_MCOUNT(TF_RIP(%rsp))
 	movq	PCPU(CURTHREAD),%rdi
 	movq	%rsp,TD_FRAME(%rdi)
@@ -474,6 +478,7 @@ IDTVEC(nmi)
 	movw	%ds,TF_DS(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	xorl	%ebx,%ebx
 	testb	$SEL_RPL_MASK,TF_CS(%rsp)
 	jnz	nmi_fromuserspace
@@ -533,6 +538,7 @@ nmi_calltrap:
 
 	shrq	$3,%rcx		/* trap frame size in long words */
 	cld
+	CLAC
 	rep
 	movsq			/* copy trapframe */
 
diff --git a/sys/amd64/amd64/identcpu.c b/sys/amd64/amd64/identcpu.c
index 2517498..27218e8 100644
--- a/sys/amd64/amd64/identcpu.c
+++ b/sys/amd64/amd64/identcpu.c
@@ -390,9 +390,36 @@ printcpuinfo(void)
 				       "\020"
 				       "\001GSFSBASE"
 				       "\002TSCADJ"
+				       "\003<b2>"
+				       "\004<b3>"
+				       "\005<b4>"
+				       "\006<b5>"
+				       "\007<b6>"
 				       "\010SMEP"
+				       "\011<b8>"
 				       "\012ENHMOVSB"
 				       "\013INVPCID"
+				       "\014<b11>"
+				       "\015<b12>"
+				       "\016<b13>"
+				       "\017<b14>"
+				       "\020<b15>"
+				       "\021<b16>"
+				       "\022<b17>"
+				       "\023<b18>"
+				       "\024<b19>"
+				       "\025SMAP"
+				       "\026<b21>"
+				       "\027<b22>"
+				       "\030<b23>"
+				       "\031<b24>"
+				       "\032<b25>"
+				       "\033<b26>"
+				       "\034<b27>"
+				       "\035<b28>"
+				       "\036<b29>"
+				       "\037<b30>"
+				       "\040<b31>"
 				       );
 			}
 
@@ -526,6 +553,9 @@ identify_cpu(void)
 		if (cpu_feature2 & CPUID2_HV) {
 			cpu_stdext_disable = CPUID_STDEXT_FSGSBASE |
 			    CPUID_STDEXT_SMEP;
+#ifdef	INTEL_SMAP
+			cpu_stdext_disable |= CPUID_STDEXT_SMAP;
+#endif	/* INTEL_SMAP */
 		} else
 			cpu_stdext_disable = 0;
 		TUNABLE_INT_FETCH("hw.cpu_stdext_disable", &cpu_stdext_disable);
diff --git a/sys/amd64/amd64/initcpu.c b/sys/amd64/amd64/initcpu.c
index 4abed4c..1f0ae6c 100644
--- a/sys/amd64/amd64/initcpu.c
+++ b/sys/amd64/amd64/initcpu.c
@@ -165,13 +165,17 @@ initializecpu(void)
 		cr4 |= CR4_FSGSBASE;
 
 	/*
-	 * Postpone enabling the SMEP on the boot CPU until the page
-	 * tables are switched from the boot loader identity mapping
-	 * to the kernel tables.  The boot loader enables the U bit in
-	 * its tables.
+	 * Postpone enabling the SMEP and the SMAP on the boot CPU until
+	 * the page tables are switched from the boot loader identity
+	 * mapping to the kernel tables.
+	 * The boot loader enables the U bit in its tables.
 	 */
 	if (!IS_BSP() && (cpu_stdext_feature & CPUID_STDEXT_SMEP))
 		cr4 |= CR4_SMEP;
+#ifdef	INTEL_SMAP
+	if (!IS_BSP() && (cpu_stdext_feature & CPUID_STDEXT_SMAP))
+		cr4 |= CR4_SMAP;
+#endif	/* INTEL_SMAP */
 	load_cr4(cr4);
 	if ((amd_feature & AMDID_NX) != 0) {
 		msr = rdmsr(MSR_EFER) | EFER_NXE;
diff --git a/sys/amd64/amd64/pmap.c b/sys/amd64/amd64/pmap.c
index 1b1c86c..8fb223a 100644
--- a/sys/amd64/amd64/pmap.c
+++ b/sys/amd64/amd64/pmap.c
@@ -98,6 +98,7 @@ __FBSDID("$FreeBSD$");
  *	and to when physical maps must be made correct.
  */
 
+#include "opt_cpu.h"
 #include "opt_pmap.h"
 #include "opt_vm.h"
 
@@ -665,6 +666,18 @@ pmap_bootstrap(vm_paddr_t *firstaddr)
 	if (cpu_stdext_feature & CPUID_STDEXT_SMEP)
 		load_cr4(rcr4() | CR4_SMEP);
 
+	if (cpu_stdext_feature & CPUID_STDEXT_SMAP)
+#ifdef	INTEL_SMAP
+		load_cr4(rcr4() | CR4_SMAP);
+	else
+		panic("The kernel compiled with \"options INTEL_SMAP\","
+			       	"but your CPU doesn't support SMAP!\n");
+#else	/* !INTEL_SMAP */
+		printf("Your CPU has support for SMAP security feature. "
+			"You should recompile the kernel with "
+			"\"options INTEL_SMAP\" to use them.\n");
+#endif	/* INTEL_SMAP */
+
 	/*
 	 * Initialize the kernel pmap (which is statically allocated).
 	 */
diff --git a/sys/amd64/amd64/support.S b/sys/amd64/amd64/support.S
index 77dbf63..9c12087 100644
--- a/sys/amd64/amd64/support.S
+++ b/sys/amd64/amd64/support.S
@@ -35,6 +35,7 @@
 #include <machine/asmacros.h>
 #include <machine/intr_machdep.h>
 #include <machine/pmap.h>
+#include <machine/smap_instr.h>
 
 #include "assym.s"
 
@@ -244,12 +245,16 @@ ENTRY(copyout)
 
 	shrq	$3,%rcx
 	cld
+	STAC
 	rep
 	movsq
+	CLAC
 	movb	%dl,%cl
 	andb	$7,%cl
+	STAC
 	rep
 	movsb
+	CLAC
 
 done_copyout:
 	xorl	%eax,%eax
@@ -290,12 +295,16 @@ ENTRY(copyin)
 	movb	%cl,%al
 	shrq	$3,%rcx				/* copy longword-wise */
 	cld
+	STAC
 	rep
 	movsq
+	CLAC
 	movb	%al,%cl
 	andb	$7,%cl				/* copy remaining bytes */
+	STAC
 	rep
 	movsb
+	CLAC
 
 done_copyin:
 	xorl	%eax,%eax
@@ -324,10 +333,12 @@ ENTRY(casuword32)
 	ja	fusufault
 
 	movl	%esi,%eax			/* old */
+	STAC
 #ifdef SMP
 	lock
 #endif
 	cmpxchgl %edx,(%rdi)			/* new = %edx */
+	CLAC
 
 	/*
 	 * The old value is in %eax.  If the store succeeded it will be the
@@ -353,10 +364,12 @@ ENTRY(casuword)
 	ja	fusufault
 
 	movq	%rsi,%rax			/* old */
+	STAC
 #ifdef SMP
 	lock
 #endif
 	cmpxchgq %rdx,(%rdi)			/* new = %rdx */
+	CLAC
 
 	/*
 	 * The old value is in %eax.  If the store succeeded it will be the
@@ -385,7 +398,9 @@ ENTRY(fuword)
 	cmpq	%rax,%rdi			/* verify address is valid */
 	ja	fusufault
 
+	STAC
 	movq	(%rdi),%rax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fuword64)	
@@ -399,7 +414,9 @@ ENTRY(fuword32)
 	cmpq	%rax,%rdi			/* verify address is valid */
 	ja	fusufault
 
+	STAC
 	movl	(%rdi),%eax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fuword32)
@@ -426,7 +443,9 @@ ENTRY(fuword16)
 	cmpq	%rax,%rdi
 	ja	fusufault
 
+	STAC
 	movzwl	(%rdi),%eax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fuword16)
@@ -439,7 +458,9 @@ ENTRY(fubyte)
 	cmpq	%rax,%rdi
 	ja	fusufault
 
+	STAC
 	movzbl	(%rdi),%eax
+	CLAC
 	movq	$0,PCB_ONFAULT(%rcx)
 	ret
 END(fubyte)
@@ -466,7 +487,9 @@ ENTRY(suword)
 	cmpq	%rax,%rdi			/* verify address validity */
 	ja	fusufault
 
+	STAC
 	movq	%rsi,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -482,7 +505,9 @@ ENTRY(suword32)
 	cmpq	%rax,%rdi			/* verify address validity */
 	ja	fusufault
 
+	STAC
 	movl	%esi,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -497,7 +522,9 @@ ENTRY(suword16)
 	cmpq	%rax,%rdi			/* verify address validity */
 	ja	fusufault
 
+	STAC
 	movw	%si,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx		/* restore trashed register */
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -513,7 +540,9 @@ ENTRY(subyte)
 	ja	fusufault
 
 	movl	%esi,%eax
+	STAC
 	movb	%al,(%rdi)
+	CLAC
 	xorl	%eax,%eax
 	movq	PCPU(CURPCB),%rcx		/* restore trashed register */
 	movq	%rax,PCB_ONFAULT(%rcx)
@@ -555,7 +584,9 @@ ENTRY(copyinstr)
 	decq	%rdx
 	jz	3f
 
+	STAC
 	lodsb
+	CLAC
 	stosb
 	orb	%al,%al
 	jnz	2b
@@ -584,7 +615,9 @@ cpystrflt_x:
 	testq	%r9,%r9
 	jz	1f
 	subq	%rdx,%r8
+	STAC
 	movq	%r8,(%r9)
+	CLAC
 1:
 	ret
 END(copyinstr)
diff --git a/sys/amd64/amd64/trap.c b/sys/amd64/amd64/trap.c
index 6fcca81..fc2d303 100644
--- a/sys/amd64/amd64/trap.c
+++ b/sys/amd64/amd64/trap.c
@@ -718,12 +718,27 @@ trap_pfault(frame, usermode)
 
 		map = &vm->vm_map;
 
+#ifdef	INTEL_SMAP
+		/*
+		 * The only case occurs when accessing the address
+		 * without the handler, is a bug, do not try to handle
+		 * it normally, and panic immediately.
+		 * SMAP related.
+		 *
+		 * PGEX_P exception delivered only by SMAP.
+		 * see intel 319433-014.pdf 9.3.3
+		 */
+		if (curpcb->pcb_onfault == NULL &&
+		    !usermode && frame->tf_err & PGEX_P) {
+			trap_fatal(frame, eva);
+			return (-1);
+		}
+#endif	/* INTEL_SMAP */
+
 		/*
 		 * When accessing a usermode address, kernel must be
 		 * ready to accept the page fault, and provide a
-		 * handling routine.  Since accessing the address
-		 * without the handler is a bug, do not try to handle
-		 * it normally, and panic immediately.
+		 * handling routine.
 		 */
 		if (!usermode && (td->td_intr_nesting_level != 0 ||
 		    curpcb->pcb_onfault == NULL)) {
diff --git a/sys/amd64/ia32/ia32_exception.S b/sys/amd64/ia32/ia32_exception.S
index fe1a676..9f13f2f 100644
--- a/sys/amd64/ia32/ia32_exception.S
+++ b/sys/amd64/ia32/ia32_exception.S
@@ -68,6 +68,7 @@ IDTVEC(int0x80_syscall)
 	movq	%r15,TF_R15(%rsp)
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp)
 	cld
+	CLAC
 	FAKE_MCOUNT(TF_RIP(%rsp))
 	movq	%rsp, %rdi
 	call	ia32_syscall
diff --git a/sys/amd64/include/asmacros.h b/sys/amd64/include/asmacros.h
index 1fb592a..c985623 100644
--- a/sys/amd64/include/asmacros.h
+++ b/sys/amd64/include/asmacros.h
@@ -167,7 +167,8 @@
 	movw	%es,TF_ES(%rsp) ;					\
 	movw	%ds,TF_DS(%rsp) ;					\
 	movl	$TF_HASSEGS,TF_FLAGS(%rsp) ;				\
-	cld
+	cld ;								\
+	CLAC
 
 #define POP_FRAME							\
 	movq	TF_RDI(%rsp),%rdi ;					\
diff --git a/sys/amd64/include/cpufunc.h b/sys/amd64/include/cpufunc.h
index 881fcd2..f959d0b 100644
--- a/sys/amd64/include/cpufunc.h
+++ b/sys/amd64/include/cpufunc.h
@@ -39,6 +39,8 @@
 #ifndef _MACHINE_CPUFUNC_H_
 #define	_MACHINE_CPUFUNC_H_
 
+#include "opt_cpu.h"
+
 #ifndef _SYS_CDEFS_H_
 #error this file needs sys/cdefs.h as a prerequisite
 #endif
@@ -711,11 +713,31 @@ intr_restore(register_t rflags)
 	write_rflags(rflags);
 }
 
+/*
+ * Intel SMAP related functions (clac and stac)
+ */
+static __inline void
+clac(void)
+{
+#ifdef	INTEL_SMAP
+	__asm __volatile(".byte x0f,0x01,0xca" : : :);
+#endif	/* INTEL_SMAP */
+}
+
+static __inline void
+stac(void)
+{
+#ifdef	INTEL_SMAP
+	__asm __volatile(".byte x0f,0x01,0xcb" : : :);
+#endif	/* INTEL_SMAP */
+}
+
 #else /* !(__GNUCLIKE_ASM && __CC_SUPPORTS___INLINE) */
 
 int	breakpoint(void);
 u_int	bsfl(u_int mask);
 u_int	bsrl(u_int mask);
+void	clac(void);
 void	clflush(u_long addr);
 void	clts(void);
 void	cpuid_count(u_int ax, u_int cx, u_int *p);
@@ -775,6 +797,7 @@ uint64_t rdtsc(void);
 u_long	read_rflags(void);
 u_int	rfs(void);
 u_int	rgs(void);
+void	stac(void);
 void	wbinvd(void);
 void	write_rflags(u_int rf);
 void	wrmsr(u_int msr, uint64_t newval);
diff --git a/sys/amd64/include/smap_instr.h b/sys/amd64/include/smap_instr.h
new file mode 100644
index 0000000..5722bbf
--- /dev/null
+++ b/sys/amd64/include/smap_instr.h
@@ -0,0 +1,14 @@
+#ifndef	__SMAP_INSTRUCTION_H
+#define	__SMAP_INSTRUCTION_H
+
+#include "opt_cpu.h"
+
+#ifdef	INTEL_SMAP
+#define	CLAC	.byte 0x0f,0x01,0xca
+#define	STAC	.byte 0x0f,0x01,0xcb
+#else	/* INTEL_SMAP_SUPPORT */
+#define	CLAC
+#define	STAC
+#endif	/* INTEL_SMAP_SUPPORT */
+
+#endif	/* __SMAP_INSTRUCTION_H */
diff --git a/sys/conf/NOTES b/sys/conf/NOTES
index 435f4b9..0912f99 100644
--- a/sys/conf/NOTES
+++ b/sys/conf/NOTES
@@ -2956,3 +2956,7 @@ options 	RCTL
 options 	BROOKTREE_ALLOC_PAGES=(217*4+1)
 options 	MAXFILES=999
 
+# Intel SMAP
+# This options supported on Haswell and/or newer CPUs (2013 Juni < ) and
+# makes the kernel unbootable on oldel CPUs.
+options 	INTEL_SMAP	# Intel's hw version of PaX uderef
diff --git a/sys/conf/options.amd64 b/sys/conf/options.amd64
index 90348b7..8b4436e 100644
--- a/sys/conf/options.amd64
+++ b/sys/conf/options.amd64
@@ -72,3 +72,6 @@ ISCI_LOGGING	opt_isci.h
 # hw random number generators for random(4)
 PADLOCK_RNG		opt_cpu.h
 RDRAND_RNG		opt_cpu.h
+
+# Intel supervisor mode access prevention (SMAP)
+INTEL_SMAP		opt_cpu.h
diff --git a/sys/x86/include/specialreg.h b/sys/x86/include/specialreg.h
index fb4a197..5437d09 100644
--- a/sys/x86/include/specialreg.h
+++ b/sys/x86/include/specialreg.h
@@ -73,6 +73,7 @@
 #define	CR4_PCIDE 0x00020000	/* Enable Context ID */
 #define	CR4_XSAVE 0x00040000	/* XSETBV/XGETBV */
 #define	CR4_SMEP 0x00100000	/* Supervisor-Mode Execution Prevention */
+#define	CR4_SMAP 0x00200000	/* Supervisor-Mode Access Prevention */
 
 /*
  * Bits in AMD64 special registers.  EFER is 64 bits wide.
@@ -283,6 +284,7 @@
 #define	CPUID_STDEXT_SMEP	0x00000080
 #define	CPUID_STDEXT_ENH_MOVSB	0x00000200
 #define	CPUID_STDEXT_INVPCID	0x00000400
+#define	CPUID_STDEXT_SMAP	0x00100000
 
 /*
  * CPUID manufacturers identifiers
-- 
1.8.2

